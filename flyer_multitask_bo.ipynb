{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flyer ML Optimization (Rebuild) â€” Multiâ€‘Task GP with Ax/BoTorch\n",
        "\n",
        "This notebook rebuilds the Bayesian Optimization pipeline so the surrogate **leverages RPM and vibration as *measured side metrics*** (not optimizable inputs). We jointly model the objective, RPM, and vibration with a **Multiâ€‘Task GP** so information can transfer across tasks and handle **partial observations**. Acquisition is optimized **only for the objective task**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup\n",
        "Uncomment installs if running in a fresh Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If needed on Colab:\n",
        "# !pip -q install ax-platform botorch gpytorch torch torchvision torchaudio\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from botorch.models.multitask import MultiTaskGP\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.fit import fit_gpytorch_model\n",
        "from botorch.acquisition import qExpectedImprovement\n",
        "from botorch.optim import optimize_acqf\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "\n",
        "torch.set_default_dtype(torch.double)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Configuration\n",
        "ðŸ‘‰ Only provide bounds for **design parameters** (variables the BO loop can suggest). You do **not** need bounds for RPM/vibration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== USER CONFIGURATION ====\n",
        "# Path to your CSV (or leave None and provide/construct df manually in next cell):\n",
        "DATA_CSV = None  # e.g., '/content/flyer_trials.csv'\n",
        "\n",
        "# Objective column to optimize (e.g., 'ld_ratio', 'lift', 'efficiency'):\n",
        "OBJECTIVE_COL = 'ld_ratio'\n",
        "\n",
        "# Side metrics available in your dataset (observed, not optimized):\n",
        "SIDE_TASKS = ['rpm', 'vibration']  # drop any that don't exist in your data\n",
        "\n",
        "# Column for vibration (should be 0/1 after mapping if needed):\n",
        "VIBRATION_COL = 'vibration'\n",
        "\n",
        "# Design parameters (optimizable inputs):\n",
        "DESIGN_VARS = [\n",
        "    # e.g., 'symmetry', 'pitch', 'chord', 'radius', 'twist'\n",
        "]\n",
        "\n",
        "# Bounds for each design var (required):\n",
        "BOUNDS: Dict[str, tuple] = {\n",
        "    # 'pitch': (10.0, 40.0),\n",
        "    # 'chord': (1.0, 3.0),\n",
        "}\n",
        "\n",
        "# Number of suggestions to propose:\n",
        "N_CANDIDATES = 5\n",
        "\n",
        "# Standardize outcomes per task:\n",
        "STANDARDIZE_Y = True\n",
        "\n",
        "# ==== END CONFIGURATION ====\n",
        "assert len(DESIGN_VARS) > 0, \"Please set DESIGN_VARS to your design parameter columns.\"\n",
        "assert set(DESIGN_VARS).issubset(set(BOUNDS.keys())), \"Bounds must be provided for all DESIGN_VARS.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load & Preprocess Data\n",
        "Expected columns: `DESIGN_VARS + [OBJECTIVE_COL] + SIDE_TASKS`. RPM numeric; vibration 0/1. Missing values are OK (handled per-task)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if DATA_CSV is not None and os.path.exists(DATA_CSV):\n",
        "    df = pd.read_csv(DATA_CSV)\n",
        "    print(f\"Loaded: {DATA_CSV}, shape={df.shape}\")\n",
        "else:\n",
        "    # Synthetic fallback so the notebook runs without your CSV\n",
        "    rng = np.random.default_rng(0)\n",
        "    if not DESIGN_VARS:\n",
        "        DESIGN_VARS.extend(['pitch', 'chord'])\n",
        "    if not BOUNDS:\n",
        "        BOUNDS.update({'pitch': (10.0, 40.0), 'chord': (1.0, 3.0)})\n",
        "    n = 100\n",
        "    pitch = rng.uniform(BOUNDS['pitch'][0], BOUNDS['pitch'][1], size=n)\n",
        "    chord = rng.uniform(BOUNDS['chord'][0], BOUNDS['chord'][1], size=n)\n",
        "    ld = (pitch - 25.0)**2 * -0.01 + (chord - 2.0)**2 * -0.2 + 10 + rng.normal(0, 0.2, size=n)\n",
        "    rpm = 3000 + 80*(pitch-25) + rng.normal(0, 50, size=n)\n",
        "    vib = (rng.random(size=n) < (0.2 + 0.1*np.clip(chord-1.0, 2.0, None))).astype(int)\n",
        "    df = pd.DataFrame({'pitch': pitch, 'chord': chord, 'ld_ratio': ld, 'rpm': rpm, 'vibration': vib})\n",
        "    print(\"Created synthetic dataset for demonstration.\")\n",
        "    display(df.head())\n",
        "\n",
        "# Ensure binary vibration if present\n",
        "if VIBRATION_COL in df.columns:\n",
        "    if not set(pd.Series(df[VIBRATION_COL]).dropna().unique()).issubset({0,1}):\n",
        "        mapping = {True:1, False:0, 'yes':1, 'no':0, 'high':1, 'low':0, 'y':1, 'n':0}\n",
        "        df[VIBRATION_COL] = df[VIBRATION_COL].map(lambda x: mapping.get(x, x)).astype(float)\n",
        "\n",
        "# Activate only tasks present in the data\n",
        "SIDE_TASKS = [t for t in SIDE_TASKS if t in df.columns]\n",
        "TASK_LIST = [OBJECTIVE_COL] + SIDE_TASKS\n",
        "print(\"Active tasks:\", TASK_LIST)\n",
        "\n",
        "# Tensor bounds for BoTorch\n",
        "bounds = torch.tensor([[BOUNDS[k][0] for k in DESIGN_VARS], [BOUNDS[k][1] for k in DESIGN_VARS]], dtype=torch.double, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Build Multiâ€‘Task Training Tensors\n",
        "We stack rows per task with a **task feature** as the last column of X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "task_to_index = {t:i for i,t in enumerate(TASK_LIST)}\n",
        "print(\"Task indices:\", task_to_index)\n",
        "\n",
        "def build_multitask_tensors(df: pd.DataFrame, design_vars: List[str], task_cols: List[str]):\n",
        "    Xs, Ys = [], []\n",
        "    for t in task_cols:\n",
        "        sub = df[design_vars + [t]].dropna()\n",
        "        if sub.empty:\n",
        "            continue\n",
        "        X = torch.tensor(sub[design_vars].to_numpy(), dtype=torch.double)\n",
        "        tfeat = torch.full((X.shape[0], 1), float(task_to_index[t]), dtype=torch.double)\n",
        "        X_mt = torch.cat([X, tfeat], dim=1)\n",
        "        y = torch.tensor(sub[t].to_numpy(), dtype=torch.double).unsqueeze(-1)\n",
        "        Xs.append(X_mt)\n",
        "        Ys.append(y)\n",
        "    X_all = torch.cat(Xs, dim=0).to(device)\n",
        "    Y_all = torch.cat(Ys, dim=0).to(device)\n",
        "    return X_all, Y_all\n",
        "\n",
        "X_all, Y_all = build_multitask_tensors(df, DESIGN_VARS, TASK_LIST)\n",
        "print(\"X_all:\", X_all.shape, \"Y_all:\", Y_all.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Fit a Multiâ€‘Task GP (ICM)\n",
        "`MultiTaskGP` learns a shared input kernel + a task covariance (coregionalization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dim = len(DESIGN_VARS)\n",
        "task_feature = input_dim\n",
        "outcome_tf = Standardize(m=1) if STANDARDIZE_Y else None\n",
        "\n",
        "mtgp = MultiTaskGP(\n",
        "    train_X=X_all,\n",
        "    train_Y=Y_all,\n",
        "    task_feature=task_feature,\n",
        "    outcome_transform=outcome_tf,\n",
        ").to(device)\n",
        "mll = ExactMarginalLogLikelihood(mtgp.likelihood, mtgp)\n",
        "fit_gpytorch_model(mll)\n",
        "mtgp.eval()\n",
        "print(\"Fitted MultiTaskGP over:\", TASK_LIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Acquisition on Objective Task Only\n",
        "We wrap the model to **append the objective task index** internally, then optimize qEI in the design space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from botorch.models.model import Model\n",
        "\n",
        "def propose_candidates(model: Model, bounds: torch.Tensor, n: int = 5, raw_samples: int = 256, q: int = 1):\n",
        "    obj_mask = (X_all[:, -1] == 0)\n",
        "    Y_obj = Y_all[obj_mask]\n",
        "    best_f = Y_obj.max()\n",
        "\n",
        "    class ObjectiveTaskModel(torch.nn.Module):\n",
        "        def __init__(self, base_model, task_index: float, d: int):\n",
        "            super().__init__()\n",
        "            self.base_model = base_model\n",
        "            self.task_index = torch.tensor(task_index, dtype=torch.double, device=Y_obj.device)\n",
        "            self.d = d\n",
        "        def posterior(self, X, output_indices=None, observation_noise=False, **kwargs):\n",
        "            if X.dim() == 2:\n",
        "                tcol = self.task_index.expand(X.shape[0], 1)\n",
        "                X_full = torch.cat([X, tcol], dim=1)\n",
        "            elif X.dim() == 3:\n",
        "                b, q, d = X.shape\n",
        "                tcol = self.task_index.expand(b*q, 1)\n",
        "                X2 = X.view(b*q, d)\n",
        "                X_full = torch.cat([X2, tcol], dim=1).view(b, q, d+1)\n",
        "            else:\n",
        "                raise RuntimeError(\"Unexpected X shape\")\n",
        "            return self.base_model.posterior(X_full, output_indices=output_indices, observation_noise=observation_noise, **kwargs)\n",
        "\n",
        "    wrapped = ObjectiveTaskModel(model, task_index=0.0, d=len(DESIGN_VARS))\n",
        "    acqf = qExpectedImprovement(model=wrapped, best_f=best_f)\n",
        "\n",
        "    cand_list = []\n",
        "    for _ in range(n):\n",
        "        cand, _ = optimize_acqf(\n",
        "            acq_function=acqf,\n",
        "            bounds=bounds,\n",
        "            q=q,\n",
        "            num_restarts=10,\n",
        "            raw_samples=raw_samples,\n",
        "        )\n",
        "        cand_list.append(cand.detach().cpu().numpy())\n",
        "    C = np.vstack(cand_list)\n",
        "    return pd.DataFrame(C, columns=DESIGN_VARS)\n",
        "\n",
        "candidates_df = propose_candidates(mtgp, bounds, n=N_CANDIDATES)\n",
        "candidates_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Save Recommendations\n",
        "Export proposed design points to CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_csv = 'next_experiments_multitask_gp.csv'\n",
        "candidates_df.to_csv(out_csv, index=False)\n",
        "out_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Optional) Singleâ€‘Task Baseline\n",
        "Fit a standard Singleâ€‘Task GP on the objective only (ignores RPM/vibration)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "obj_mask = (X_all[:, -1] == 0)\n",
        "X_obj = X_all[obj_mask][:, :len(DESIGN_VARS)]\n",
        "Y_obj = Y_all[obj_mask]\n",
        "\n",
        "stgp = SingleTaskGP(train_X=X_obj, train_Y=Y_obj, outcome_transform=Standardize(m=1) if STANDARDIZE_Y else None).to(device)\n",
        "mll2 = ExactMarginalLogLikelihood(stgp.likelihood, stgp)\n",
        "fit_gpytorch_model(mll2)\n",
        "stgp.eval()\n",
        "\n",
        "best_f = Y_obj.max()\n",
        "acq_st = qExpectedImprovement(model=stgp, best_f=best_f)\n",
        "cand_st, _ = optimize_acqf(\n",
        "    acq_function=acq_st,\n",
        "    bounds=bounds,\n",
        "    q=1,\n",
        "    num_restarts=10,\n",
        "    raw_samples=256,\n",
        ")\n",
        "baseline_df = pd.DataFrame(cand_st.detach().cpu().numpy(), columns=DESIGN_VARS)\n",
        "baseline_out = 'next_experiments_single_task_gp.csv'\n",
        "baseline_df.to_csv(baseline_out, index=False)\n",
        "baseline_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- You **do not** provide bounds for RPM/vibration (they are *observed outputs*, not inputs).\n",
        "- Partial observations are fine: MTGP learns task correlations and shares strength.\n",
        "- If vibration is string/categorical, map to 0/1 before training.\n",
        "- To integrate with Ax, wrap this fitted BoTorch model in a custom Ax `BotorchModel` and fix the task feature to 0 in evaluation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}